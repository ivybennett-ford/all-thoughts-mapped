---
title: Atlas of AI
author: Kate Crawford
publication-date: '2021:00:00'
tags:
  - data
  - data-science
  - ethical-data-science
  - environment
  - maps
  - justice
  - equity
  - structural-racism
  - structural-inequality
  - SN
  - in-staging
---
# Atlas of AI: Politics, Power, and the Planetary Cost of Artificial Intelligence by Kate Crawford
## Running Notes
##### Introduction
- [[clever-hans-effect]]
	- How is intelligence 'created'?
- Why and when can deep -- not shallow networks avoid the 'curse of dimensionality'?
	- Poggio et al
- What is [[artificial-intelligence]]?
	- It is [[knowledge]] refining
	- It is an attempt to understand and build intelligent entities
- Ursula Franklin
- Measurement is a political act:
>"[AI as the sole way of [[knowledge|knowing]]] colonizing impulse centralizes [[power]] in the AI field: it determines how the world is measured and defined while simultaneously denying that it is an inherently political activity." (Crawford, 11)

- Crawford urges the reader to ground the process of AI in its physical body.
- True Time (Google)
- ML as an artifact of "normative reasoning"
- Affect recognition
- "Abstraction and Extraction"
##### Earth (I)
- Marshall McLuhan's take on media
- *A Geology of Media* by Jussi Parikka
- Extractivism
- *A Prehistory of the Cloud* by Tung-Hui Hu
- From extraction to exsanguination
##### [[labor]] (II)
- *Wages Against Housework* by Silvia Federici
- "The Work Discipline and Industrial Capitalism" by Thompson
##### [[data]] (III)
- Crawford uses this section to describe the [[physical-cost-of-data-capitalism]]. Maintaining data as a form of [[capital]] induces harm for the lower classes, while maximizing profits for the upper class. Not only does data-capitalism exist in the real world, alongside real people's homes, it exists in there bodies. Data describes, and it becomes a comorbidity with poverty and racism.
- According to those who benefit the most from the pipeline, AI is merely "a tool with 'minimal risk'," especially when it's been boiled down to "a form of applied math with few consequences for human subjects." But it's this kind of careless thinking that leads to the most devastating outcomes. The AI [[design|designer]] must ask themselves if the consequences equitably distributed regardless of identity. Futhermore, the designer must ask themselves *who wants what they are designing*. The drive for [[capital-interferes-with-need-fulfillment]].
- Data was not always viewed as a form of capital. This changed as the [[neoliberalism]] view of markets as optimal channels of income and workers. The privileged in society who possess strong "data signals" -- minimal to no debt, a high paying job, a college degree, white -- are literally afforded better data outcomes, i.e., a higher credit score, or other such measurable benefits.
	- ![[goodharts-law]]
- ###### The Arm's Length Paradigm
	- Developing AI might be good for the planet and all our various cultures over all if we stop pretending that the environmental consequences are dramatically different for the people who live closest to the structures required to maintain the supply chain.
	- *Data Violence and How Bad Engineering Choices Can Damage Society* by Anna Lauren Hoffman
	- Individuals who benefit from the supply chain must recognize their own involvement, their own *distance* from the finite causes of harm.
- ##### Classification (IV)
- The practice of [[classification|classification]] is the centralization of power.